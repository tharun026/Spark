Innova Solutions:

1. Lineage Graph vs DAG in Spark
RDD Lineage is for a single RDD on how it will be transformed from source to destination. 
DAG is a culmination of RDD's and the actions that will be performed on them

2. Spline in Spark

3. RDD vs DataFrame vs Dataset

4. Parameters for spark submit
executorMemory, driverMemory, executor cores, broadcast threshold, 

5. How Spark works internally
6. struct type - collection of struct fields. 
used to define the schema of a dataframe.
val schema = StructType(Seq(
    StructField("field1",StringType,true),
    StructField("field2",StringType,true)))
val data = Seq(
    Row("abc","def"),
    Row("ghi","jkl"))
val df = spark.createDataFrame(spark.sparkContext.parallelize(data),schema)
This also provides us the option to define nested structures.
val schema = new StructType()
  .add("name", new StructType()
    .add("firstName", StringType)
    .add("lastName", StringType))
  .add("id", IntegerType)
This will create the name column as a list with values.
Ex:
name            | id
[tharun,kumar]  | 1
[x,y]           | 2

7. steps in EMR
option to submit spark jobs from EMR console.
8. rdd functions
9. jfrog
10. scheduling jobs in aws
11. udfs in spark
12. overview of build tool. sbt or maven

Purchasing Power:

1. Datalake vs Datawarehouse vs Datamart
2. Slowly Changing Dimension
3. Star vs Snowflake schema
In the center is a fact table surrounded by a lot of dimension tables. Dimension tables are not normalized.
Ex: Dimension table patients will have physical address, city, state name and country columns
Snowflake is an extension of Star schema, where Dimension tables are normalized.
Ex: Dimension table patients will have only zip code. We will have another table from which we can calculate the address.
4. Functional Programming
Declarative type of programming. It's main focus is on what to solve instead of how to solve
Pure functions - functions with no side effects
Avoiding mutable data
Recursion
Functions are first class and can be of higher order

L&T
1. Traits in scala
2. Monads in scala
3. auxillary constructors in scala
Used for construcotr overloading. https://www.geeksforgeeks.org/scala-auxiliary-constructor/
4. Higher Order Functions
5. var val - var variable, mutable. val, immutable
6. Accumulators in Spark
7. How to connect to RDBMS database in spark
8. case classes vs struct type
9. descructor in scala

Paypal
1. list of 1 to 100 is stored in 4 partitions. if we coalesce it to 2 partitions, how will the data be stored, equally or inequally?
Data will be distributed inequally during coalesce. Repartition creates equal sized partitions.
2. read csv file and split words based on a delimiter and look for a particular word and save it down as csv again
spark.read.csv(path)

3. what is hive metastore
4. what happens when you do msck repair table
loses the partition details stored in metastore and regenerates the partition list for the metastore


